
import torch   #–æ—Å–Ω–æ–≤–Ω–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ –¥–ª—è –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
from torchvision import transforms  #–º–æ–¥—É–ª—å –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å
from torchvision import models #–º—ñ—Å—Ç–∏—Ç—å –≥–æ—Ç–æ–≤—ñ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –º–æ–¥–µ–ª–µ–π (–≤ —Ç.—á. resnet50).
from torch import nn  #–º–æ–¥—É–ª—å –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂.
import torch.nn.functional as F #—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π API –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü—ñ–πF.relu, F.softmax, F.sigmoid, –≤—Ç—Ä–∞—Ç(loss): F.cross_entropy, F.mse_loss, F.nll_loss ,–ª—ñ–Ω—ñ–π–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó: F.linear, F.conv2d, F.batch_norm nn —Å—Ç–≤–æ—Ä—é—î –æ–±'—î–∫—Ç (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –º–æ–¥—É–ª—å), –∞ F ‚Äî –≤–∏–∫–ª–∏–∫–∞—î –æ–ø–µ—Ä–∞—Ü—ñ—é –±–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç–∞–Ω—É.
import PIL.Image  #–¥–ª—è –≤—ñ–¥–∫—Ä–∏—Ç—Ç—è —Ç–∞ –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å.
# üîß –ö–ª–∞—Å –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ ResNet50
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ResNet50
        resnet= models.resnet50(pretrained=True)
        for param in resnet.parameters():
            param.requires_grad = False

        # –ó–∞–º—ñ–Ω—é—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —à–∞—Ä –Ω–∞ Identity
        resnet.fc = nn.Identity()
        self.resnet = resnet

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ ResNet —è–∫ –ø—ñ–¥–º–µ—Ä–µ–∂—É
        self.linear = nn.Linear (2048, 2)

    def forward(self, x):
        out = self.resnet(x)
        out = self.linear(out)
        return out


# üì¶ –§—É–Ω–∫—Ü—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
def load_model(weights_path: str) -> MyModel:
    model = MyModel()
    model.load_state_dict(torch.load('data/model_weights.pth', weights_only=True))
    model.eval()
    return model


# üñºÔ∏è –§—É–Ω–∫—Ü—ñ—è –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
def preprocess_image(image_path: str) -> torch.Tensor:
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    image = PIL.Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)


# üîç –§—É–Ω–∫—Ü—ñ—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
def predict(model: MyModel, image_tensor: torch.Tensor, classes: list[str]) -> str:
    with torch.no_grad():
        logits = model(image_tensor)
        probabilities = F.softmax(logits, dim=1)
        predicted_idx = probabilities.argmax().item()

    print(f"–ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ: {probabilities.numpy()}")
    print(f"–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ: {classes[predicted_idx]}")
    return classes[predicted_idx]


# üöÄ –û—Å–Ω–æ–≤–Ω–∏–π –±–ª–æ–∫ –∑–∞–ø—É—Å–∫—É
if __name__ == "__main__":
    model_path = "data/model_weights.pth"
    image_path = "data/000000000023.jpg"
    class_labels = ['bird', 'drone']

    model = load_model(model_path)
    image_tensor = preprocess_image(image_path)
    result = predict(model, image_tensor, class_labels)